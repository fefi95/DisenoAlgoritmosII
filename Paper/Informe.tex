\documentclass{ci5652}
\usepackage{graphicx,amssymb,amsmath}
\usepackage[utf8]{inputenc}
% \usepackage[spanish]{babel}
\usepackage{hyperref}
\usepackage{subfigure}
\usepackage{paralist}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
\usepackage{csvsimple}
\usepackage[none]{hyphenat}

%-------------------------- Macros and Definitions ----------------------------%

% Add all additional macros here, do NOT include any additional files.

% The environments theorem (Theorem), invar (Invariant), lemma (Lemma),
% cor (Corollary), obs (Observation), conj (Conjecture), and prop
% (Proposition) are already defined in the ci5652.cls file.

%------------------------------------------------------------------------------%
%                                                                              %
%                                  TÍTULO                                      %
%                                                                              %
%------------------------------------------------------------------------------%

\title{Metaheurísticas para el problema de Aprendizaje de Pesos en Características}

\author{Stefani Castellanos
        \and
        Erick Silva}

%------------------------------------------------------------------------------%
%                                                                              %
%                                CONTENIDO                                     %
%                                                                              %
%------------------------------------------------------------------------------%

\begin{document}
\thispagestyle{empty}
\maketitle

%------------------------------------------------------------------------------%
%                                 RESUMEN                                      %
%------------------------------------------------------------------------------%

\begin{abstract}
*Inserte una descripción breve del paper.*

Palabras claves: Aprendizaje de Pesos en Características, Metaheurísticas,
\textit{Machine Learning}.
\end{abstract}

%------------------------------------------------------------------------------%
%                                INTRODUCCIÓN                                  %
%------------------------------------------------------------------------------%

\section*{Introducción}
% NO ESTÁ COMPLETO
Debido a la gran cantidad de información manejada actualmente, ha surgido la
necesidad de reducir el tamaño de dichos datos, sin embargo, esto genera el
problema de escoger correctamente que información es relevante para el
clasificador.\cite{Cano_2003} \\

Reducir el tamaño de los datos es posible a través de los siguientes métodos:

\begin{itemize}
  \item Seleccionando características del conjunto de datos, lo que reduce el
  tamaño de las columnas.
  \item Eliminando las instancias del conjunto de datos que aporte poca
  información.
  \item Determinando la importancia de las características, ya que proporciona
  información que permite guiar al clasificador y así, reducir el tiempo de
  procesamiento.
\end{itemize}

Este trabajo se enfocará en esta última, denominado el problema de \textit{Aprendizaje
de Pesos en Características}. Se utilizará un algoritmo \textit{greedy} (ávido)
denomindado RELIEF, dos metaheurísticas de trayectoría y dos poblacionales,
para finalmente compararlas y determinar cual de ellos es más adecuado para el
problema.

%------------------------------------------------------------------------------%
%                          DESCRIPCIÓN DEL PROBLEMA                            %
%------------------------------------------------------------------------------%

\section{Descripción del problema}

Antes de describir el problema APC, es necesario comprender en qué consiste
un problema de clasificación; se dispone de un conjunto de posibles clases
($C$) y un conjunto de datos ($X$), en donde una instancia $x_i$ es un vector
previamente clasificado y de la forma:
$$x_i = \langle f_1, f_2, \dots, f_n, c\rangle $$ en donde:

\begin{itemize}
  \item $f_i$ : el valor de cada característica.
  \item $n$ : la cantidad de característcas.
  \item $c$ : la clase a la que pertenece dicha instancia, con $c \in C$.
  \item $|X| = m$: cantidad de instancias.
  \item $|C| = p$ : cantidad de clases.
\end{itemize}

Es común particionar $X$ en dos subconjuntos que representen el conjunto de
entrenamiento y el de prueba, $Xe$ y $Xp$ respectivamente, de manera que $X?e$
pueda ser utilizado para que el algoritmo aprenda los parámetros que le
permitan clasificar correctamente todas sus instancias y utilizar $X_p$ para
validar los resultados obtenidos.\\

El problema del APC consiste en optimizar el rendimiento de un clasificador, a
partir de la inclusión de pesos asociados a las características del conjunto de
datos. Estos pesos ponderan la relevancia de cada característica en y modifican
su valor al momento de calcular las distancias entre instancias, de tal forma 
que los clasificadores que se construyan a partir de estos pesos sean certeros 
y/o más rápidos. En este caso en particular, el clasificador considerado será el
\textit{K-Nearest Neighbor} (K-vecinos más cercanos) con $K=1$ (1-NN).\\

El algoritmo K-NN asume que todas las instancias corresponden a puntos en un
espacio $n$-dimensional ($\Re^n$), en donde $n$ es la cantidad de
características del conjunto de datos. \cite{Mitchell_1997}. El algoritmo es el
siguiente:

\begin{algorithm}
 \DontPrintSemicolon
 \vspace*{0.1cm}
 \KwIn{Conjunto de entrenamiento $X_e$, Conjunto de prueba $X_p$, $K$}
 \KwOut{Conjunto $X_p$ clasificados según $C$}
  \ForEach{$x_i \in X_p$}{
   vecinos = [ ];\;
   \ForEach{$x_j \in X_e$}{
    d = distancia($x_i, x_j$);\;
    agregar($x_j, d, vecinos$);\;
   }
  k\_vecinos = seleccionar\_cercanos($k, vecinos$);\;
  clasificar($x_i, k\_vecinos$);\;
 }
 \KwRet{$X_p$ clasificado}
 \vspace*{0.1cm}
 \caption{K-Nearest Neighbor}
\end{algorithm}

El proceso de aprendizaje de este clasificador consiste en almacenar una tabla
con las instancias correspondientes al $X_e$ junto a la clase asociada a cada 
uno de ellos. Dado una instancia $x_i \in X_p$, se calcula su distancia a todas
las otras que pertenecen al conjunto de entrenamiento y se escogen las $k$ más
cercanas \cite{Herrera_2017}; usualmente se determina la proximidad entre dos
ejemplos utilizando la distancia Euclideana. Finalmente, $x_i$ se clasifica  
según la clase mayoritaria grupo y se retorna el conjunto de pruebas clasificado.

%-------------------------- FUNCIÓN OBJETIVO ----------------------------------%

\subsection{Función objetivo}

Al ser APC un problema de optimización, es necesario establecer cual es la 
función que se desea mejorar. En este caso, dadas las características del
problema, resulta evidente que obtener una "buena" solución está fuertemente
relacionado con la cantidad de instancias clasificadas correctamiente usando
1-NN. El objetivo es encontrar el mejor vector de pesos que permita máximizar la
tasa de aciertos del clasificador 1-NN. Más específicamente:

\begin{equation}
  Max\ tasa(\text{1-NN}(X, W)) = 100 \times \frac{aciertos(X)}{total(X)}
\end{equation}

sujeto a:
\[
w_i = [0, 1] \ \ 1 \leq i \leq n
\]

donde:
\begin{itemize}
  \item $W = \langle w_1, \dots, w_n\rangle$ es una solución al problema.
  \item 1-NN es el clasificador k-NN con $k=1$ vecinos, generado a partir del
  conjunto de datos inicial. La distancia entre dos instancias se calculará 
  con la distancia euclideana pesada: 
  $$\sqrt{\sum_{i=1}^n (w_i * (x'_i - x''_i))^{2}}$$
  \item $X$ es el conjunto de datos sobre el que se evalúa el clasificador.
  \item $aciertos$ es la cantidad de instancias de $X$ clasificadas 
  correctamente por 1-NN.
  \item $total$ es la cantidad total de instancias de $X$.
\end{itemize}

%---------------------- REPRESENTACIÓN DE LA SOLUCIÓN -------------------------%

\subsection{Representación de la solución}

La solución al problema de Aprendizaje de Pesos en Características viene dado 
por $W = \langle w_1, \dots, w_n\rangle$, un vector de números reales de tamaño
$n$ (cantidad de características) en el que el valor de cada $w_i$  define el
peso que pondera a la  característica $f_i$, es decir, representa que tan
importante para distinguir un ejemplo de otro.\\

Cada $w_i$ debe pertenecer al intervalo $[0,1]$; los valores cercanos a 1 indican
que la característica es más importante. En caso de que algún valor quede fuera
de este intervalo, se debe normalizar, seleccionando al máximo valor del vector
y dividiendo todos los valores entre dicho número. 

%------------------------------------------------------------------------------%
%                             ALGORITMO RELIEF                                 %
%------------------------------------------------------------------------------%
\section{Algoritmo Relief}

Es un algoritmo para escoger características inspirado en el aprendizaje basado 
en instancias, detecta aquellos ejemplos que son estadísticamente relevantes 
para el concepto objetivo en tiempo lineal ($\Theta(nmp)$). Utiliza un 
\textit{threshold}, $\tau$ entre $0 \leq \tau \leq 1$ , que codifica la 
relevancia de una característica en particular \cite{Kira_1992};  en esta 
versión será omitido este parámetro puesto que las metaheurísticas utilizan el 
vector de pesos y no el vector de relevancias que se obtiene con $\tau$.\\

Relief utiliza la distancia euclideana $n$-dimensional para determinar el "amigo
más cercano" y el "enemigo más cercano" de una instancia $x_i$. Se denomina a 
una instancia "amigo más cercano" o "near-hit" a la instancia que pertenezca a 
la misma clase de $x_i$ y se encuentre a menor distancia. Se denomina a una 
instancia "enemigo más cercano" o "near-miss" a la instancia que pertenezca a 
una clase diferente a $x_i$ y se encuentre a menor distancia \cite{Kira_1992}.

\begin{algorithm}
 \DontPrintSemicolon
 \vspace*{0.1cm}
 \KwIn{Conjunto de entrenamiento $X_e$}
 \KwOut{Vector de pesos $W$}
  W = {0, 0 \dots, 0}\;
  \ForEach{$x_i \in X_e$}{
   a = amigo\_mas\_cercano($x_i$);\;
   e = enemigo\_mas\_cercano($x_i$);\;
   \;
   /* Actualizar pesos de $W$ */\;
   \For{$i \dots n$}{
    dif\_amigo = diferencia($x_i, a$);\;
    dif\_enemigo = diferencia($x_i, e$);\;
    $w_i$ = $w_i$ - dif\_amigo + dif\_enemigo;\;
   }
  }
  normalizar($W$);\;
 \KwRet{$W$}
 \vspace*{0.1cm}
 \caption{RELIEF}
\end{algorithm}

La diferencia entre el valor $x_i$ y el amigo/enemigo más cercano está definido 
por: 
- Para los atributos con valores numéricos:
$$\text{diferencia}(a,b) = {(a - b)}^{2}$$
- Para los atributos con valores nominales:
\[
\text{diferencia}(a,b) = 
  \begin{cases}
    0 & \text{son el iguales}\\
    1 & \text{son diferentes}
  \end{cases} 
\]
%------------------------------------------------------------------------------%
%                              METAHEURÍSTICAS                                 %
%------------------------------------------------------------------------------%

\section{Metaheurísticas}

Las soluciones a muchos problemas de optimización son intratables, es decir,
obtener la mejor respuesta podría tomar un tiempo potencialmente infinito, no 
ser resoluble o no se dispone de la capacidad computacional suficiente para
resolverlo. Las metaheurísticas constituyen un conjunto de estrategías para 
guiar heurísticas a encontrar soluciones aceptables en un tiempo razonable para
resolver un problema difícil o del que no se dispone información completa
\cite{Talbi_2009}. Usualmente poseen un componente estocástico, por lo que la
solución depende de las variables aleatorias generadas y se describen los
resultados basados en resultados empíricos. Existen tres tipos de 
metaheurísticas: de trayectoria, poblacionales e hibridas.\\

En general, las meteheurísticas mejoran soluciones obtenidas anteriormentes. Sus
componentes principales son:

\begin{itemize}
  \item Inicialización. Se requiere alguna solución inicial según la 
  representación del problema particular, esta puede ser generada de manera
  aleatoria o utilizando algun algoritmo \textit{greedy}.
  \item Operador de vecindad. Se debe disponer de un algortimo que, a partir de
  otra solución, genere un conjunto de soluciones "vecinas". Este operador puede
  entenderse como una pequeña perturbación en alguna componente de la 
  representación utilizada.
  \item Criterio de selección. Entre las soluciones que pertenecen a la 
  vecindad, se debe escoger la "mejor". Existe diversas políticas, las más
  conocidas son: el mejor de toda la vecindad, el primer mejor y el mejor de una
  porción de la vecindad. La escogencia de algun criterio sobre otro depende del
  problema.
  \item Criterio de convergencia. Al mejorar una solución a partir de la 
  anterior, es necesario contar con algún mecanismo que permita detener la
  ejecución de la metaheurística y devolver alguna solución. Los más conocidos
  son: detenerse al encontrar el óptimo (si este es conocido), luego de un 
  número fijo de iteraciones y luego de un número fijo de iteraciones sin 
  cambiar la mejor solución.
\end{itemize}

\subsection{Metaheurísticas de trayectoria}

Al resolver un problema de optimización, las metaheurísticas de trayectoria,
utilizan una solución y realizan mejoras sobre esta, iterativamente; pueden ser
entendidas como "caminatas" sobre el espacio de búsqueda del problema. 
Probablemente la metaherística de trayectoria más conocida es 
\textit{Local Search}, esta toma una solución inicial, encuentra sus vecinos y
escoge el mejor según un criterio \cite{Talbi_2009}. 

\subsubsection{Búsqueda Local Iterada (Iterated Local Search)}

\textit{Local Search} podría quedar atrapado en un óptimo local y jamás llegar al global ya que se encarga de intensificar la búsqueda, por esta razón ILS supone una mejora sobre LS. Es una de las metaheurísticas más fáciles de implementar, primero se aplica LS a la solución inicial; luego, en cada iteración, se realiza una perturbación del óptimo local y se repite el proceso hasta un cumplir el criterio de aceptación \cite{Talbi_2009}.

%Algoritmo

\subsubsection{Recocido Simulado (Simulated Annealing)}

Su nombre proviene del proceso físico de recocer sólidos, en el que un sólido cristalino es calentado y luego se deja enfriar muy lentamente hasta que alcance su configuración más estable y estructuralmente superior, por lo tanto está libre de defectos del cristal \cite{Glover_2003}. En términos de resolver un problema de optimización, el sólido representa una solución, "calentarlo" es perturbar la solución hasta que la temperatura se estabilice y el "enfriamiento" es una función no-creciente.\\

En cada iteración, Simulated Annealing, genera dos posibles soluciones: la actual y otra, las cuales son comparadas. Las soluciones que mejoren la actual son siempre aceptadas y existe una función que permite escoger alguna considerada "inferior" y así, escapar de un mínimo local. La probabilidad de aceptar una solución que no mejora depende de la temperatura, que típicamente es una función no-creciente en cada iteración del algoritmo y al aproximarse la temperatura a cero la probabilidad de aceptar una solución que no mejora es menor \cite{Glover_2003}. La temperatura sólo decrece cuando se ha alcanzado una condición de equilibrio.\\ 

% Algoritmo



\subsection{Metaheurísticas poblacional}

La mayoría de estos algoritmos están inspirados en fenómenos naturales y el
comportamiento de los animales. Estas metaheurísticas toman una población
inicial que está constituida por un conjunto de posibles soluciones del 
problema. Luego, iterativamente, se generan nuevos individuos (soluciones) a
través de "cruces" y mutaciones en los genes (componentes del vector), los 
cuales son seleccionados para reemplazar a algunos de la actual población,
creando una nueva. Este proceso se repite hasta alcanzar un criterio de 
convergencia dado \cite{Talbi_2009}.\\ 

Los cruces puede ser entendidos como una combinación de dos individuos de la
población para crea unos nuevos, preservando algunas características de los
originales. El operador de mutación efectúa una perturbación de un hijo 
generado; el propósito de este es realizar variaciones en la población que
permitan explorar nuevos lugares en el espacio de solución, es decir, 
diversificar la búsqueda. 

\subsubsection{Scatter Search}

Es un metaheurística evolutiva y poblacional que recombina soluciones 
seleccionadas de un "conjunto de referencia" para construir otras nuevas. El
método comienza generando una población inicial cuyos individuos satisfacen un
criterio de diversidad y calidad. El conjunto de referencia es construido
seleccionando buenas representaciones de la población las cuales son combinadas
para proveer otras iniciales y luego mejorarlas con procedimientos basados en
metaheurísticas de trayectoria como \textit{Local Search}. De acuerdo con este
procedimiento, el conjunto de referencia es actualizado para que contenga
soluciones de buena calidad y otras que permitan diversificar la búsqueda. El
proceso itera hasta que un criterio de parada se satisface \cite{Talbi_2009}.\\

Scatter Search aprovecha la información proveída por una heurística para crear
las soluciones "buenas" e intensificar la búsqueda alrededor de estos espacios. 

% Algoritmo

\subsubsection{Differential Evolution}

Es un algoritmo evolutivo que genera su población inicial de manera aleatoria y
con un tamaño mayor o igual a 4. Suele utilizarse para problemas de optimización
contínuos pues cada individuo tiene componentes con números reales.\\ 

El operador de cruce que utiliza está basado en la combinación líneal de las
soluciones utilizando la distancia entre las mismas. Dado un padre $x$ y tres
otro individuos seleccionados aleatoriamente $r1, r2$ y $r3$ se crea un nuevo
vector $u = r1 + F(r2 - r3)$. $F$ representa un factor permite añadir un peso o
importancia a la diferencia entre $r2$ y es tal que $r3$ y $F \in (0, 1)$
\cite{Glover_2003}. Finalmente $u$ se combina con $x$, para crear $x'$, de la
siguiente manera: 

\[
x'_i = 
  \begin{cases}
    u_i & \text{si } j < CR\\
    x_i & \text{si } j \geq CR 
  \end{cases} 
\]

donde: 
\begin{itemize}
  \item $CR \in (0,1)$ : un parámetro que representa la probabilidad.
  \item $j$ : el número aleatorio entre 0 y 1 para escoger un componente u otro.
  \item $1 \leq i \leq n $ : índice para cada característica.
\end{itemize}

% Algoritmo

%------------------------------------------------------------------------------%
%                              IMPLEMENTACIÓN                                  %
%------------------------------------------------------------------------------%

\section{Implementación}
*Inserte Implementación*

%--------------------------- CONJUNTO DE DATOS --------------------------------%

\subsection{Conjunto de datos}

Con la expansión del área de Inteligencia Artificial, se ha convertido en una
necesidad contar con bases de datos que proporcionen información que permita a
los investigadores, educadores y estudiantes del área realizar análisis sobre 
los algoritmos de \textit{Machine Learning}. Una de las librerias más populares
en la actualidad es UCI Machine Learning Repository, que mantiene una colección
de conjuntos de datos, teorías de dominio y generadores de datos disponibles 
para toda la comunidad.\\

Para efectuar el análisis de las metaherísticas a utilizar para resolver el
problema APC se utilizarán cuatro librerias disponibles en 
\href{http://archive.ics.uci.edu/ml/index.php}{UCI}:

\begin{description}
  \item [Iris:] este es probablemente el conjunto de datos mejor conocido y citado
  en la literatura de reconocimiento de patrones. Contiene tres clases de 50
  instancias cada una, en donde cada clase corresponde a un tipo de planta Iris.
  Cada instancia posee las siguientes características: largo del sépalo, ancho 
  del sépalo, largo del pétalo y ancho del pétalo en centímetros. Las clases a
  predecir son: "Iris-Setosa", "Iris-Versicolor" e "Iris-Virginica". 
  \cite{UCI_Iris}.
  
  \item [Sonar:] es una base de datos de detección de materiales mediante señales 
  de sónar que "rebotan" en los objetos desde diferentes ángulos y bajo 
  condiciones varias, discriminando entre cilindros metálicos(\textit{mines}) y
  rocas(\textit{rocks}). Cuenta con 111 \textit{mines} y 97 \textit{rocks} donde
  cada instancia es un conjunto de 60 números entre 0.0 y 1.0 que representan la
  energía entre una banda en particular, integrada sobre un periodo dispuestas 
  en orden cresciente según el ángulo. Las clases a predecir son: "R"
  (\textit{rocks}) y "M" (\textit{mines}). \cite{UCI_Sonar}.
   
  \item [Winsconsin Diagnostic Breast Cancer:] es una base de datos contiene
  atributos calculados a partir de una imagen digitalizada de una aspiración con
  aguja fina de una masa en la mama. Se describen las características de los
  núcleos de las células presentes en la imagen. La tarea consiste en determinar
  si un tumor encontrado es benigno o maligno. Cuenta con 357 tumores beningnos
  y 212 malignos en donde cada instancia posee 30 caracteristicas, 10 valores
  reales computados por cada célula: radio, textura, perímetro, área, suavidad,
  compacto, concavidad, puntos cóncavos, simetría y dimensión fractal.
  \cite{UCI_WDBC}.

  \item [Spam Base:] es una base de datos de detección de SPAM (correo basura)
  frente a correo electrónico seguro. Cuenta de 4601 ejemplos y 57 atributos en
  donde los primeros 48 corresponden al porcentaje de frecuencia de una palabra
  en particular en un correo, 6 corresponden al porcentaje de frecuencia de
  símbolos de puntuación y las últimas 3 son el promedio, máximo y la suma de la
  cantidad de letras en mayúsculas. Las clases a predecir son: 1 (spam), 0 
  (non-spam) que representan \cite{UCI_SpamBase}.
  
\end{description}


%------------------------------------------------------------------------------%
%                                RESULTADOS                                    %
%------------------------------------------------------------------------------%

\section{Resultados}
*Inserte Resultados*\\
%\csvreader[
%  respect all, 
%  autotabular
%  ]{statistics/iris/no_weights.csv}{}{\csvlinetotablerow}%
%\\
%\csvreader[
%  respect all, 
%  autotabular
%  ]{statistics/sonar/no_weights.csv}{}{\csvlinetotablerow}%
%\\
%\csvreader[
%  respect all, 
%  autotabular
%  ]{statistics/spambase/no_weights.csv}{}{\csvlinetotablerow}%
%\\
%\csvreader[
%  respect all, 
%  autotabular
%  ]{statistics/wdbc/no_weights.csv}{}{\csvlinetotablerow}%
%\\
%RELIEF\\
%\csvreader[
%  respect all, 
%  autotabular
%  ]{statistics/iris/relief.csv}{}{\csvlinetotablerow}%
%\\
%\csvreader[
%  respect all, 
%  autotabular
%  ]{statistics/sonar/relief.csv}{}{\csvlinetotablerow}%
%\\
%\csvreader[
%  respect all, 
%  autotabular
%  ]{statistics/spambase/relief.csv}{}{\csvlinetotablerow}%
%\\
%\csvreader[
%  respect all, 
%  autotabular
%  ]{statistics/wdbc/relief.csv}{}{\csvlinetotablerow}%

%------------------------------------------------------------------------------%
%                               CONCLUSIONES                                   %
%------------------------------------------------------------------------------%

\section*{Conclusiones}

Aquí concluyen.

%------------------------------ Bibliography ---------------------------------%

% Please add the contents of the .bbl file that you generate,  or add bibitem entries manually if you like.
% The entries should be in alphabetical order
\small
\bibliographystyle{abbrv}

\begin{thebibliography}{99}

\bibitem{Cano_2003}
Cano, J. Herrera, F. Lozano. M
\newblock Using evolutionary algorithms as Instance Selection for data
reduction in KDD: an experimental study.
\newblock {\em IEEE Transaction on Evolutionary computation}, 2003.

\bibitem{UCI_Iris}
Fisher, R.A. (1988). UCI Machine Learning Repository 
\newblock [\url{https://archive.ics.uci.edu/ml/machine-learning-databases/iris/}].
\newblock Irvine, CA: University of California, School of Information and Computer Science.

\bibitem{Glover_2003}
Glover, F
\newblock Handbook of metaheuristics. 
\newblock {\em Operation resarch and management science}, 2003.

\bibitem{Herrera_2017}
Herrera, F.
\newblock Metaheurísticas. 
\newblock {\em Seminario 2: Problemas de optimización con técnicas
basadas en búsqueda local}, 2017. Disponible en: 
\url{http://sci2s.ugr.es/sites/default/files/files/Teaching/GraduatesCourses/Metaheuristicas/Sem02-Problemas-BusquedaLocal-MHs-16-17.pdf}

\bibitem{UCI_SpamBase}
Hopkins, M. (1999). UCI Machine Learning Repository 
\newblock [\url{https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/}].
\newblock Irvine, CA: University of California, School of Information and Computer Science.

\bibitem{Kira_1992}
Kira, K., Rendell, A.
\newblock A practical approach to feature selection, 1992.

\bibitem{Mitchell_1997}
Mitchell, T.
\newblock Machine Learning.
\newblock {\em From Book News, Inc}, 1997.

\bibitem{UCI_Sonar}
Sejnowski, T (año). UCI Machine Learning Repository 
\newblock [\url{http://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/}].
\newblock Irvine, CA: University of California, School of Information and Computer Science.

\bibitem{Talbi_2009}
Talbi E.
\newblock Metaheuristics: From desing to implementation
\newblock {\em University of Lille}, 2009.

\bibitem{UCI_WDBC}
Wolberg, W. (1995). UCI Machine Learning Repository 
\newblock [\url{https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/}].
\newblock Irvine, CA: University of California, School of Information and Computer Science.

%----TODO: ELIMINAR BIBITEM ----%
%\bibitem{so2005}
%EJEMPLO C. So and H. So.
%\newblock A groundbreaking result.
%\newblock {\em Journal of Everything}, 59(2):23--37, 2005.
%
\end{thebibliography}


\newpage
\section*{Apéndice}

Bla.

%------------------------ EL EJEMPLO DE LA PROFE -----------------------------%
%
%\section{La sección de ejemplo de la profe}
%Citan así~\cite{so2005}. ELIMINAR AL ESCRIBIR EL INFORME
%
%\begin{algorithm}
% \DontPrintSemicolon
% \vspace*{0.1cm}
% \KwIn{Descripcion}
% \KwOut{Descripcion}
% Primer paso\;
% Segundo\;
% \ForEach{$i = 1\dots n$}{
%  \If{Alguna condición}{
%   Algo aqui\;
%   }
% }
% \KwRet{Valor}
% \vspace*{0.1cm}
% \caption{Nombre}
%\end{algorithm}
%
\end{document}